{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import en_core_web_sm\n",
    "from spacy import displacy\n",
    "from spacy.symbols import nsubj, VERB,  NOUN, PROPN, PRON, ADP, CCONJ,PUNCT\n",
    "\n",
    "from spacy.errors import Errors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import swifter\n",
    "\n",
    "import sys, os, re\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./incoPat_225509/*.xls')\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    try:\n",
    "        dfs.append(pd.read_excel(f))\n",
    "    except Exception as e:\n",
    "        print(\"{0}: {1}\".format(f, e))\n",
    "\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noun_chunks(doclike):\n",
    "    \"\"\"\n",
    "    Detect base noun phrases from a dependency parse. Works on both Doc and Span.\n",
    "    \"\"\"\n",
    "    labels = [\n",
    "        \"nsubj\",\n",
    "        \"dobj\",\n",
    "        \"nsubjpass\",\n",
    "        \"pcomp\",\n",
    "        \"pobj\",\n",
    "        \"dative\",\n",
    "        \"appos\",\n",
    "        \"attr\",\n",
    "        \"ROOT\",\n",
    "    ]\n",
    "    doc = doclike.doc  # Ensure works on both Doc and Span.\n",
    "\n",
    "    if not doc.is_parsed:\n",
    "        raise ValueError(Errors.E029)\n",
    "\n",
    "    np_deps = [doc.vocab.strings.add(label) for label in labels]\n",
    "    conj = doc.vocab.strings.add(\"conj\")\n",
    "    np_label = doc.vocab.strings.add(\"NP\")\n",
    "    prev_end = -1\n",
    "    for i, word in enumerate(doclike):\n",
    "        if word.pos not in (NOUN, PROPN, PRON):\n",
    "            continue\n",
    "        # Prevent nested chunks from being produced\n",
    "        if word.left_edge.i <= prev_end:\n",
    "            continue\n",
    "        if word.dep in np_deps:\n",
    "            prev_end = word.i\n",
    "            yield word.left_edge.i, word.i +1, np_label\n",
    "        elif word.dep == conj:\n",
    "            head = word.head\n",
    "            while head.dep == conj and head.head.i < head.i:\n",
    "                head = head.head\n",
    "            # If the head is an NP, and we're coordinated to it, we're an NP\n",
    "            if head.dep in np_deps:\n",
    "                prev_end = word.i\n",
    "                yield word.left_edge.i, word.i+1, np_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/docs/usage/processing-text\n",
    "def construct_graph(x, edges, labels):\n",
    "    sl = (PUNCT, ADP, CCONJ)\n",
    "    kl = (NOUN, PROPN, PRON)\n",
    "    doc = nlp(x)\n",
    "#     print('document: {0}'.format(doc))\n",
    "    # Load spacy's dependency tree into a networkx graph\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for nc in list(noun_chunks(doc)):\n",
    "            if nc[0] != nc[1]:\n",
    "                retokenizer.merge(doc[nc[0]:nc[1]])\n",
    "                edges.append((doc[nc[0]:nc[1]].lemma_.upper(), doc[nc[0]:nc[1]].lemma_.upper()))\n",
    "    for token in doc:\n",
    "        if token.pos not in kl:\n",
    "            continue\n",
    "        # FYI https://spacy.io/docs/api/token\n",
    "        for child in token.children:\n",
    "            if child.pos not in kl:\n",
    "                continue\n",
    "            # edges.append(('{0}-{1}'.format(token.lower_,token.i),'{0}-{1}'.format(child.lower_,child.i)))\n",
    "            edges.append((token.lemma_.upper(), child.lemma_.upper()))\n",
    "            #labels[(token.lower_, child.lower_)] = child.dep_\n",
    "        # edges.append((token.head.lower_, token.lower_))\n",
    "    return doc\n",
    "# https://networkx.github.io/documentation/networkx-1.10/reference/algorithms.shortest_paths.html\n",
    "# print(nx.shortest_path_length(graph, source='robots-0', target='awesomeness-11'))\n",
    "# print(nx.shortest_path(graph, source='robots-0', target='awesomeness-11'))\n",
    "# print(nx.shortest_path(graph, source='robots-0', target='agency-15'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 是否需要过滤低词频的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "labels = {}\n",
    "df['parsed_title'] = df['标题(英)'].apply(lambda x: construct_graph(x, edges, labels))\n",
    "graph = nx.DiGraph(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end_nodes = [x for x in graph.nodes() if (graph.out_degree(x)<=1 and graph.in_degree(x)<=2) or (x.count(' ') >= 4 or  x.count(' ') < 1)]\n",
    "graph.remove_edges_from(nx.selfloop_edges(graph))\n",
    "end_nodes = [x for x in graph.nodes() if graph.in_degree(x)<=1] # TODO something wrong ,self edge exclude?\n",
    "# TODO something wrong ,self edge exclude?\n",
    "for en in end_nodes:\n",
    "    graph.remove_node(en)\n",
    "\n",
    "graph.remove_edges_from(nx.selfloop_edges(graph))\n",
    "sub_nodes = []\n",
    "for nd in graph.nodes():\n",
    "    if graph.out_degree(nd) + graph.in_degree(nd) > 10:\n",
    "        sub_nodes.append(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(graph, './tmp/kws1000_graphml.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(noun_chunks(nlp(u'ADDITIVELY MANUFACTURED HEAT TRANSFER DEVICE')))\n",
    "doc = nlp(u'POLAR ADDITIVE FOR THE SYNTHESIS OF COPOLYMERS OF VINYLAROMATIC MONOMER AND CONJUGATED DIENE MONOMER HAVING HIGH VINYLAROMATIC AND LOW VINYL CONTENTS')\n",
    "list(doc.noun_chunks)\n",
    "# list(noun_chunks(doc))\n",
    "doc = construct_graph(u'POLAR ADDITIVE FOR THE SYNTHESIS OF COPOLYMERS OF VINYLAROMATIC MONOMER AND CONJUGATED DIENE MONOMER HAVING HIGH VINYLAROMATIC AND LOW VINYL CONTENTS',[],[])\n",
    "options = {\"color\": \"white\", \"collapse_phrases\" : True, \"bg\": \"#000000\"}\n",
    "displacy.serve(doc, style=\"dep\",options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-05d6a5703dc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbipartite_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashdot'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwith_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# pos=nx.circular_layout(graph),nx.spring_layout(graph,scale=4, k= 0.6)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./tmp/kws_graph.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#nx.draw_networkx_edge_labels(graph, pos = nx.spring_layout(graph), edge_labels = labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(64, 64))\n",
    "nx.draw(graph, pos=nx.bipartite_layout(graph, sub_nodes),width=0.2, style='dashdot',with_labels=True) # pos=nx.circular_layout(graph),nx.spring_layout(graph,scale=4, k= 0.6)\n",
    "# plt.show()\n",
    "plt.savefig(\"./tmp/kws_graph.png\")\n",
    "#nx.draw_networkx_edge_labels(graph, pos = nx.spring_layout(graph), edge_labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank_scipy(graph, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dict = collections.OrderedDict()\n",
    "re_ = r\"^A |^THE |^THEIR |^ITS |^THIS |^AN |^SUCH A |^AS |^TO |^AND |^-PRON- |AT LEAST|USE THEREOF|^OR | THEREOF| THEREFOR| THERETO| THEREFROM| THEREBY\"\n",
    "for k, v in sorted(pr.items(), key=lambda item: item[1], reverse=True):\n",
    "    k = re.sub(re_, \"\", k.upper())\n",
    "    if  k.count(' ') < 4 and  k.count(' ') >= 1 and k.count('(') == 0 and k.count(')') == 0:\n",
    "        filter_dict[k] = v\n",
    "filter_df = pd.DataFrame.from_dict(filter_dict, orient='index', columns=['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df.head(1000).to_excel('./out/kws_dp_pagerank.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, a = nx.hits(graph)\n",
    "{k: v for k, v in sorted(a.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "graph.remove_edges_from(nx.selfloop_edges(graph))\n",
    "sub_graph_k_core = nx.k_core(graph, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub_graph_k_core.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(sub_graph_k_core, './tmp/sub_graph_k{0}.graphml'.format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_dict = nx.onion_layers(graph.to_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = 1\n",
    "onion_k = {k: v for k, v in onion_dict.items() if v==ko}\n",
    "onion_k_graph = graph.subgraph(list(onion_k.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onion_k_graph.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(onion_k_graph, './tmp/onion_k{0}.graphml'.format(ko))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "kt =6\n",
    "k_truss = nx.k_truss(graph.to_undirected(),kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230503"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k_truss.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(k_truss, './tmp/k_truss_k{0}.graphml'.format(kt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (jupyterProject)",
   "language": "python",
   "name": "pycharm-29c72c67"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
